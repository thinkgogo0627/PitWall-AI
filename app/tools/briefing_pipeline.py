import asyncio
from app.tools.hard_data import analyze_race_data
from app.tools.soft_data import get_event_timeline
from llama_index.llms.google_genai import GoogleGenAI
import os

# LLM ì§ì ‘ í˜¸ì¶œìš© (Agent Loop ì•ˆ ê±°ì¹¨)
llm = GoogleGenAI(model="models/gemini-2.5-flash", api_key=os.getenv("GOOGLE_API_KEY"))

async def generate_quick_summary(year, gp, driver_focus=None):
    """
    [Fast Pipeline] 
    ReAct ë£¨í”„ ì—†ì´ ë°ì´í„°ë¥¼ ë³‘ë ¬ë¡œ ê¸ì–´ì˜¨ ë’¤, ë‹¨ í•œ ë²ˆì˜ LLM í˜¸ì¶œë¡œ ìš”ì•½ë³¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        query_topic = f"{year} {gp}"
        
        # 1. ë°ì´í„° ë³‘ë ¬ ìˆ˜ì§‘ (Parallel Execution) - ì†ë„ì˜ í•µì‹¬!
        # ê²°ê³¼ ë°ì´í„°ì™€ íƒ€ì„ë¼ì¸(ì‚¬ê³ /ì´ìŠˆ)ì„ ë™ì‹œì— ê°€ì ¸ì˜µë‹ˆë‹¤.
        results_task = asyncio.to_thread(analyze_race_data, query_topic)
        timeline_task = asyncio.to_thread(get_event_timeline, query_topic)
        
        results, timeline = await asyncio.gather(results_task, timeline_task)
        
        # 2. í”„ë¡¬í”„íŠ¸ ì¡°ë¦½ (Context Injection)
        prompt = f"""
        ë‹¹ì‹ ì€ F1 ìˆ˜ì„ ì €ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ Raw Dataë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¸Œë¦¬í•‘ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        
        [RAW DATA]
        - Race Results: {results}
        - Key Events (Timeline): {timeline}
        - Focus Driver: {driver_focus if driver_focus else "Winner & Key Players"}

        [ì‘ì„± ì§€ì¹¨]
        1. **ì„œì‚¬(Narrative) ê°•ì¡°:** ë‹¨ìˆœíˆ ìˆœìœ„ë§Œ ë‚˜ì—´í•˜ì§€ ë§ê³ , íƒ€ì„ë¼ì¸ì„ ì°¸ê³ í•˜ì—¬ "ì–´ë–»ê²Œ ê·¸ ìˆœìœ„ê°€ ë˜ì—ˆëŠ”ì§€" ì„¤ëª…í•˜ì„¸ìš”.
           (ì˜ˆ: "ì›ë˜ 5ìœ„ì˜€ìœ¼ë‚˜ ì•ì„  ì°¨ëŸ‰ì˜ ì‹¤ê²©(DSQ)ìœ¼ë¡œ ì¸í•´ 3ìœ„ë¡œ í¬ë””ì›€ì— ì˜¬ëìŠµë‹ˆë‹¤.")
        2. **ê²°ì •ì  ìˆœê°„:** íƒ€ì„ë¼ì¸ì—ì„œ 'Retirement', 'Crash', 'Penalty', 'DSQ' í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ê°•ì¡°í•˜ì„¸ìš”.
        3. **í•œêµ­ì–´**ë¡œ ëª…í™•í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        4. ì¶œë ¥ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ í—¤ë“œë¼ì¸, ê²½ê¸° ìš”ì•½, ì£¼ìš” ì´ìŠˆ(DNF/DSQ) ìˆœìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
        """

        # 3. ë‹¨ë°œì„± ì¶”ë¡  (One-shot Generation)
        response = await llm.acomplete(prompt)
        return str(response)

    except Exception as e:
        return f"ğŸš¨ íŒŒì´í”„ë¼ì¸ ì—ëŸ¬ ë°œìƒ: {str(e)}"