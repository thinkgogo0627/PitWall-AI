# data_pipeline/crawlers/f1_news.py

import traceback
import trafilatura # [NEW] ì „ìš© ë„êµ¬ ì„í¬íŠ¸
from bs4 import BeautifulSoup # (ì œëª© ì¶”ì¶œìš©ìœ¼ë¡œ ë‚¨ê²¨ë‘ )
from datetime import datetime

from .base import BaseSeleniumCrawler
from domain.documents import F1NewsDocument

class AutosportCrawler(BaseSeleniumCrawler):
    
    def set_extra_driver_options(self, options) -> None:
        # ... (ê¸°ì¡´ ìŠ¤í…”ìŠ¤/Eager ì„¤ì • ìœ ì§€) ...
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option("useAutomationExtension", False)
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        options.page_load_strategy = 'eager'

    def extract(self, link: str, **kwargs) -> dict:
        print(f" Autosport ì§„ì… ì¤‘: {link}")
        
        try:
            self.driver.get(link)
            # Eager ëª¨ë“œë¼ ê¸ˆë°© ë¦¬í„´ë˜ì§€ë§Œ, trafilaturaë¥¼ ìœ„í•´ HTMLì´ ì¢€ ë” ì°¨ì˜¤ë¥¼ ì‹œê°„ì„ 1ì´ˆ ì •ë„ ì¤Œ
            import time
            time.sleep(1) 
            
            html_source = self.driver.page_source

            # [Step 1] ì œëª© ì¶”ì¶œ (ì´ê±´ BS4ê°€ ë¹ ë¦„)
            soup = BeautifulSoup(html_source, "html.parser")
            title_tag = soup.find("h1")
            title = title_tag.get_text(strip=True) if title_tag else "No Title"

            # [Step 2] ë³¸ë¬¸ ì¶”ì¶œ (Trafilatura ì—”ì§„ ì‚¬ìš©) ğŸš€
            # include_comments=False: ëŒ“ê¸€ ì œê±°
            # include_tables=False: í‘œ ë°ì´í„° ì œê±° (í•„ìš”í•˜ë©´ True)
            # no_fallback=True: ì •í™•ë„ ìš°ì„  (ì“°ë ˆê¸° ê¸ëŠë‹ˆ ì•ˆ ê¸ê² ë‹¤)
            body_content = trafilatura.extract(
                html_source, 
                include_comments=False, 
                include_tables=False,
                no_fallback=False 
            )

            if not body_content:
                # Trafilaturaê°€ ì‹¤íŒ¨í•˜ë©´ ê°„ë‹¨í•œ ë°±ì—… (ë©”íƒ€ íƒœê·¸ ë“±)
                description = soup.find("meta", attrs={"name": "description"})
                body_content = description["content"] if description else "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨"
                print(f" Trafilatura ì¶”ì¶œ ì‹¤íŒ¨ -> Meta Descriptionìœ¼ë¡œ ëŒ€ì²´")

            # [Step 3] ì‘ì„±ì ì¶”ì¶œ (ê¸°ì¡´ ìœ ì§€)
            author_tag = soup.find("a", class_="ms-item_author")
            author = author_tag.get_text(strip=True) if author_tag else "Unknown"

            news_doc = F1NewsDocument(
                title=title,
                content=body_content,
                url=link,
                platform="Autosport",
                author=author,
                published_at=datetime.now(),
                is_embedded=False
            )
            
            print(f" ì¶”ì¶œ ì™„ë£Œ: {title} ({len(body_content)}ì)")
            return news_doc.dict()

        except Exception as e:
            print(f" Autosport í¬ë¡¤ë§ ì‹¤íŒ¨")
            print(traceback.format_exc())
            return {}