import asyncio
from motor.motor_asyncio import AsyncIOMotorClient
from beanie import init_beanie

# ë„ë©”ì¸ ëª¨ë¸ & í¬ë¡¤ëŸ¬ ì„í¬íŠ¸
from domain.documents import F1NewsDocument
from data_pipeline.crawlers.f1_tactic import Formula1Crawler


async def test_crawler_logic():
    print("ğŸ”Œ MongoDB ì‹œë™(Fuel Injection) ì¤‘...")
    
    # ---------------------------------------------------------
    # 1. í•„ìˆ˜: DB ì—°ê²° (ì´ê²Œ ìˆì–´ì•¼ Documentë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŒ!)
    # ---------------------------------------------------------
    mongo_uri = "mongodb://admin:password123@localhost:27017"
    try:
        client = AsyncIOMotorClient(mongo_uri)
        # pitwall_dbì— F1NewsDocument ë“±ë¡
        await init_beanie(database=client.pitwall_db, document_models=[F1NewsDocument])
        print("âœ… DB ì—°ê²° ì„±ê³µ! (Ready to Race)")
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    # ---------------------------------------------------------
    # 2. í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘
    # ---------------------------------------------------------
    crawler = Formula1Crawler()
    
    # ê¸°ì‚¬ ëª©ë¡ í˜ì´ì§€ (Tactic/Analysis íƒœê·¸)
    target_list_url = "https://www.formula1.com/en/latest/tags/analysis.3HkjTN75peeCOsSegCyOWi"
    
    # (1) ëª©ë¡ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
    print(f"\nğŸš€ [TEST] ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘ (íƒ€ê²Ÿ: {target_list_url})")
    # í…ŒìŠ¤íŠ¸ë‹ˆê¹Œ 1~2ë²ˆë§Œ í´ë¦­í•´ì„œ ë¹ ë¥´ê²Œ í™•ì¸
    article_links = crawler.crawl_listing_page(target_list_url, max_clicks=2)
    
    print(f"ğŸ“¦ ì´ {len(article_links)}ê°œì˜ ë§í¬ í™•ë³´!")
    if not article_links:
        print("âŒ ë§í¬ ìˆ˜ì§‘ ì‹¤íŒ¨")
        return

    # (2) ê°œë³„ ê¸°ì‚¬ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (ì²« ë²ˆì§¸ ë§í¬ë¡œ)
    target_article = article_links[0]
    print(f"\nğŸš€ [TEST] ê°œë³„ ê¸°ì‚¬ ìƒì„¸ ìˆ˜ì§‘: {target_article}")
    
    # ì´ì œ DBê°€ ì—°ê²°ë˜ì–´ ìˆìœ¼ë‹ˆ ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ì•ˆ ë‚¨!
    result = crawler.extract(target_article)
    
    if result and result.get('title'):
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f" - ì œëª©: {result['title']}")
        print(f" - ë³¸ë¬¸ ê¸¸ì´: {len(result['content'])}ì")
        print(f" - í”Œë«í¼: {result['platform']}")
    else:
        print("âŒ ì‹¤íŒ¨: ë‚´ìš©ì„ ê°€ì ¸ì˜¤ì§€ ëª»í•¨")

    # ë¸Œë¼ìš°ì € ì¢…ë£Œ
    crawler.driver.quit()

if __name__ == "__main__":
    asyncio.run(test_crawler_logic())