{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46850136",
   "metadata": {},
   "source": [
    "# ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì„ ìœ„í•œ ê²€ì¦ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "1. êµ­ë‚´ ë°ì´í„° ì†ŒìŠ¤\n",
    "\n",
    "- 1-1. ì§€í”¼ì½”ë¦¬ì•„\n",
    "    - RAGì˜ ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤ìš©ìœ¼ë¡œ í™œìš©\n",
    "    - BeatifulSoupë¡œ ê¸ì–´ì˜¤ê¸°\n",
    "\n",
    "- 1-2. ë„¤ì´ë²„ ìŠ¤í¬ì¸ (ëª¨í„°ìŠ¤í¬ì¸  ì¼ë°˜)\n",
    "\n",
    "-------------------------------------------\n",
    "\n",
    "2. í•´ì™¸ ë°ì´í„° ì†ŒìŠ¤\n",
    "\n",
    "- í¬ë¡¤ë§ -> Geminië¡œ ë²ˆì—­ -> DBì— ì €ì¥\n",
    "- í¬ë¡¤ë§ -> DBì— ì €ì¥ -> english encoder ì‚¬ìš©\n",
    "\n",
    "- 2-1. Autosport/Motorsport.com\n",
    "    - JustText, Trafilatura << ë³¸ë¬¸ ì¶”ì¶œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©\n",
    "\n",
    "- 2-2. Formula1.com(ê³µí™ˆ)\n",
    "    - Race Strategy Analysis\n",
    "    - Selenium , Playwright\n",
    "\n",
    "\n",
    "-----------------------------------------------\n",
    "\n",
    "3. FIA ê³µì‹ ê·œì •ì§‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2c77de",
   "metadata": {},
   "source": [
    "### Trial 1 >> GPKorea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0adc44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì ‘ì† URL: http://www.gpkorea.com/news/articleList.html?sc_section_code=S1N2&view_type=sm\n",
      "ì‘ë‹µ ìƒíƒœ: 200\n",
      "\n",
      "[íŒ¨í„´ ë°œê²¬] 'h4 a'ë¡œ 21ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n",
      "--- ìƒìœ„ 5ê°œ ì œëª© ---\n",
      "1. 'ì±”í”„ íƒ„ìƒ' ê¶Œì˜¤íƒ, ë¬¸ì²´ë¶€ì¥ê´€ë°° KICì»µ ì¹´íŠ¸ë ˆì´ì‹± ì¢…í•©ìš°ìŠ¹\n",
      "2. WRC ìµœì¢…ì „ 'ì‚¬ìš°ë”” ë ë¦¬' ê°œë§‰â€¦í•œêµ­íƒ€ì´ì–´, 'ë‹¤ì´ë‚˜í”„ë¡œ' ë…ì  ê³µê¸‰\n",
      "3. F1 ë§¥ë¼ë Œ ë…¸ë¦¬ìŠ¤Â·í”¼ì•„ìŠ¤íŠ¸ë¦¬ `ì¶©ê²©ì˜ ì‹¤ê²©`â€¦ìŠ¤í‚¤ë“œ ë¸”ë¡ ê·œì • ìœ„ë°˜\n",
      "4. \"ì´ëŸ´ ìˆ˜ê°€...\" F1 í˜ë¥´ìŠ¤íƒ€íœ, ë¼ìŠ¤ë² ì´ê±°ìŠ¤GP ìš°ìŠ¹ '24ì ì°¨ ì¢í˜”ë‹¤'\n",
      "5. F1 í˜ë¥´ìŠ¤íƒ€íœ â€œë‚´ë…„ ì‹œì¦Œì—” 3ë²ˆê³¼ 69ë²ˆìœ¼ë¡œ ë°”ê¾¸ê² ë‹¤\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def check_what_is_in_s1n2():\n",
    "    # ë‹˜ê»˜ì„œ ì„¤ì •í•˜ì‹  ê·¸ URL ê·¸ëŒ€ë¡œ!\n",
    "    url = \"http://www.gpkorea.com/news/articleList.html?sc_section_code=S1N2&view_type=sm\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0'\n",
    "    }\n",
    "    \n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    \n",
    "    print(f\"ì ‘ì† URL: {url}\")\n",
    "    print(f\"ì‘ë‹µ ìƒíƒœ: {res.status_code}\")\n",
    "    \n",
    "    # ì§€í”¼ì½”ë¦¬ì•„ì˜ ëª¨ë“  ê°€ëŠ¥í•œ ì œëª© íƒœê·¸ íŒ¨í„´ì„ ë‹¤ ì°”ëŸ¬ë´…ë‹ˆë‹¤.\n",
    "    selectors = [\n",
    "        \".list-titles a\",\n",
    "        \".list-block .tit a\",\n",
    "        \"h4 a\",\n",
    "        \".list-body a\" \n",
    "    ]\n",
    "    \n",
    "    found_any = False\n",
    "    \n",
    "    for selector in selectors:\n",
    "        titles = soup.select(selector)\n",
    "        if titles:\n",
    "            print(f\"\\n[íŒ¨í„´ ë°œê²¬] '{selector}'ë¡œ {len(titles)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n",
    "            print(\"--- ìƒìœ„ 5ê°œ ì œëª© ---\")\n",
    "            for i, t in enumerate(titles[:5]):\n",
    "                print(f\"{i+1}. {t.get_text(strip=True)}\")\n",
    "            found_any = True\n",
    "            break # í•˜ë‚˜ ì°¾ì•˜ìœ¼ë©´ ì¤‘ë‹¨\n",
    "            \n",
    "    if not found_any:\n",
    "        print(\"\\nëª¨ë“  íŒ¨í„´ìœ¼ë¡œë„ ì œëª©ì„ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤. HTML êµ¬ì¡°ê°€ ì™„ì „íˆ ë‹¤ë¥¸ê°€ ë´…ë‹ˆë‹¤.\")\n",
    "        # ì´ ê²½ìš° HTMLì„ í†µì§¸ë¡œ ë´ì•¼ ì•Œ ìˆ˜ ìˆì–´ì„œ, í˜¹ì‹œë‚˜ í•´ì„œ body ì¼ë¶€ë¥¼ ì¶œë ¥\n",
    "        print(\"HTML ì¼ë¶€:\", soup.body.get_text()[:200])\n",
    "\n",
    "check_what_is_in_s1n2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "599dadf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ê¸°ì‚¬ 21ê°œ ì¤‘ F1 ê¸°ì‚¬ë¥¼ ì„ ë³„í•©ë‹ˆë‹¤...\n",
      "[ìˆ˜ì§‘ ì™„ë£Œ] F1 ë§¥ë¼ë Œ ë…¸ë¦¬ìŠ¤Â·í”¼ì•„ìŠ¤íŠ¸ë¦¬ `ì¶©ê²©ì˜ ì‹¤ê²©`â€¦ìŠ¤í‚¤ë“œ ë¸”ë¡ ê·œì • ìœ„ë°˜\n",
      "[ìˆ˜ì§‘ ì™„ë£Œ] \"ì´ëŸ´ ìˆ˜ê°€...\" F1 í˜ë¥´ìŠ¤íƒ€íœ, ë¼ìŠ¤ë² ì´ê±°ìŠ¤GP ìš°ìŠ¹ '24ì ì°¨ ì¢í˜”ë‹¤'\n",
      "[ìˆ˜ì§‘ ì™„ë£Œ] F1 í˜ë¥´ìŠ¤íƒ€íœ â€œë‚´ë…„ ì‹œì¦Œì—” 3ë²ˆê³¼ 69ë²ˆìœ¼ë¡œ ë°”ê¾¸ê² ë‹¤\"\n",
      "[ìˆ˜ì§‘ ì™„ë£Œ] `í˜ë¼ë¦¬ F1 ì˜ì…ì„¤' í˜¸ë„ˆ...ìœŒë¦¬ì—„ìŠ¤-ìºë”œë½-ì• ìŠ¤í„´ë§ˆí‹´ì€ \"NO!\"\n",
      "[ìˆ˜ì§‘ ì™„ë£Œ] â€œF1ì—ì„œ ë°°ìš°ëŠ” ì¡°ì§ ì „ëµâ€â€¦ë³€ë™ì‹ ì „ í˜‘íšŒì¥ `F1 ë¦¬ë”ì‹­` ì¶œê°„\n",
      "[ìˆ˜ì§‘ ì™„ë£Œ] \"F1ì´ ë³„ê±°ì•¼\" ì „ê¸° ì½˜ì…‰íŠ¸ì¹´ 'DGR-Lola' ê³µê°œâ€¦ëª¨ë‚˜ì½” ì„œí‚· 11ì´ˆ ì•ì„œ\n",
      "[ìˆ˜ì§‘ ì™„ë£Œ] 'ë°ë·” ì´ˆì½ê¸°' ì•„ìš°ë”” F1, ìµœê°• ë“œë¼ì´ë²„ í˜ë¥´ìŠ¤íƒ€íœ ì˜ì… ë…¸ë¦¬ë‚˜\n",
      "[ìˆ˜ì§‘ ì™„ë£Œ] í˜ë¼ë¦¬ F1íŒ€, ê¸°ì—…ê°€ì¹˜ MLB ì œì¹˜ê³  9ì¡° ì›ëŒ€...'ë¯¸êµ­ì˜ í˜'\n",
      "[ìˆ˜ì§‘ ì™„ë£Œ] 'í‹°íƒ€ëŠ„-ë¸”ë™-ë ˆë“œ' ì•„ìš°ë””, F1 ë°ë·” ì•ë‘ê³  `R26 ì½˜ì…‰íŠ¸` ê³µê°œâ€¦â€œ2030ë…„ ì±”í”¼ì–¸ ë„ì „â€\n",
      "ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼: 9ê°œì˜ F1 ê¸°ì‚¬ í™•ë³´!\n",
      "                                         title\n",
      "0       F1 ë§¥ë¼ë Œ ë…¸ë¦¬ìŠ¤Â·í”¼ì•„ìŠ¤íŠ¸ë¦¬ `ì¶©ê²©ì˜ ì‹¤ê²©`â€¦ìŠ¤í‚¤ë“œ ë¸”ë¡ ê·œì • ìœ„ë°˜\n",
      "1  \"ì´ëŸ´ ìˆ˜ê°€...\" F1 í˜ë¥´ìŠ¤íƒ€íœ, ë¼ìŠ¤ë² ì´ê±°ìŠ¤GP ìš°ìŠ¹ '24ì ì°¨ ì¢í˜”ë‹¤'\n",
      "2             F1 í˜ë¥´ìŠ¤íƒ€íœ â€œë‚´ë…„ ì‹œì¦Œì—” 3ë²ˆê³¼ 69ë²ˆìœ¼ë¡œ ë°”ê¾¸ê² ë‹¤\"\n",
      "3      `í˜ë¼ë¦¬ F1 ì˜ì…ì„¤' í˜¸ë„ˆ...ìœŒë¦¬ì—„ìŠ¤-ìºë”œë½-ì• ìŠ¤í„´ë§ˆí‹´ì€ \"NO!\"\n",
      "4       â€œF1ì—ì„œ ë°°ìš°ëŠ” ì¡°ì§ ì „ëµâ€â€¦ë³€ë™ì‹ ì „ í˜‘íšŒì¥ `F1 ë¦¬ë”ì‹­` ì¶œê°„\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def crawl_gpkorea_final():\n",
    "    # 1. URL: ëª¨í„°ìŠ¤í¬ì¸  ì¢…í•© ì„¹ì…˜ (S1N2)\n",
    "    url = \"http://www.gpkorea.com/news/articleList.html?sc_section_code=S1N2&view_type=sm\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # 2. ìš”ì²­ ë° ì¸ì½”ë”© ì„¤ì •\n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    \n",
    "    articles = []\n",
    "    \n",
    "    # 3. F1 í‚¤ì›Œë“œ (í•„í„°ë§)\n",
    "    # í™”ë©´ì— ë³´ì´ëŠ” 'ë§¥ë¼ë Œ', 'ë…¸ë¦¬ìŠ¤', 'í˜ë¥´ìŠ¤íƒ€íœ' ë“±ì´ ë‹¤ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "    f1_keywords = ['F1', 'í¬ë®¬ëŸ¬1', 'í¬ë®¬ëŸ¬ 1', 'ê·¸ë‘í”„ë¦¬', 'GP', \n",
    "                   'ë² ë¥´ìŠ¤íƒ€íœ', 'í•´ë°€í„´', 'ë¥´í´ë ˆë¥´', 'í˜ë¼ë¦¬', 'ë ˆë“œë¶ˆ', 'ë©”ë¥´ì„¸ë°ìŠ¤', 'ë§¥ë¼ë Œ', 'ë…¸ë¦¬ìŠ¤']\n",
    "\n",
    "    # 4. â˜… í•µì‹¬ ìˆ˜ì •: ë””ë²„ê·¸ì—ì„œ ì„±ê³µí•œ 'h4 a' ì„ íƒì ì‚¬ìš©\n",
    "    rows = soup.select(\"h4 a\") \n",
    "\n",
    "    print(f\"ì „ì²´ ê¸°ì‚¬ {len(rows)}ê°œ ì¤‘ F1 ê¸°ì‚¬ë¥¼ ì„ ë³„í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "    for row in rows:\n",
    "        title = row.get_text(strip=True)\n",
    "        link = \"http://www.gpkorea.com\" + row['href']\n",
    "        \n",
    "        # 5. í•„í„°ë§ ë¡œì§\n",
    "        if any(keyword in title for keyword in f1_keywords):\n",
    "            print(f\"[ìˆ˜ì§‘ ì™„ë£Œ] {title}\")\n",
    "            \n",
    "            try:\n",
    "                # ìƒì„¸ í˜ì´ì§€ ë³¸ë¬¸ ìˆ˜ì§‘\n",
    "                sub_res = requests.get(link, headers=headers)\n",
    "                sub_res.encoding = 'utf-8'\n",
    "                sub_soup = BeautifulSoup(sub_res.content, 'html.parser')\n",
    "                \n",
    "                # ë³¸ë¬¸ ID\n",
    "                content_div = sub_soup.select_one(\"#article-view-content-div\")\n",
    "                \n",
    "                if content_div:\n",
    "                    content = content_div.get_text(strip=True)\n",
    "                    \n",
    "                    # ë…¸ì´ì¦ˆ ì œê±°\n",
    "                    if \"Copyright\" in content:\n",
    "                        content = content.split(\"Copyright\")[0]\n",
    "                    \n",
    "                    articles.append({\n",
    "                        \"title\": title,\n",
    "                        \"link\": link,\n",
    "                        \"context\": content\n",
    "                    })\n",
    "                    time.sleep(0.1) # ë§¤ë„ˆ ë”œë ˆì´\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  â”” ì—ëŸ¬: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            # F1 ê¸°ì‚¬ê°€ ì•„ë‹ˆë©´ íŒ¨ìŠ¤ (ë¡œê·¸ í™•ì¸ìš©)\n",
    "            # print(f\"  [íŒ¨ìŠ¤] {title}\") \n",
    "            pass\n",
    "            \n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "df = crawl_gpkorea_final()\n",
    "print(f\"ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼: {len(df)}ê°œì˜ F1 ê¸°ì‚¬ í™•ë³´!\")\n",
    "if not df.empty:\n",
    "    print(df[['title']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85787417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1 ë§¥ë¼ë Œ ë…¸ë¦¬ìŠ¤Â·í”¼ì•„ìŠ¤íŠ¸ë¦¬ `ì¶©ê²©ì˜ ì‹¤ê²©`â€¦ìŠ¤í‚¤ë“œ ë¸”ë¡ ê·œì • ìœ„ë°˜</td>\n",
       "      <td>http://www.gpkorea.com/news/articleView.html?i...</td>\n",
       "      <td>ì‚¬ì§„=ë§¥ë¼ë Œ F1 íŒ€ í˜ì´ìŠ¤ë¶í¬ë®¬ëŸ¬ ì›(F1) ë§¥ë¼ë Œ íŒ€ì´ ë¼ìŠ¤ë² ì´ê±°ìŠ¤ ê·¸ë‘í”„ë¦¬ ê²°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"ì´ëŸ´ ìˆ˜ê°€...\" F1 í˜ë¥´ìŠ¤íƒ€íœ, ë¼ìŠ¤ë² ì´ê±°ìŠ¤GP ìš°ìŠ¹ '24ì ì°¨ ì¢í˜”ë‹¤'</td>\n",
       "      <td>http://www.gpkorea.com/news/articleView.html?i...</td>\n",
       "      <td>ì‚¬ì§„=ë ˆë“œë¶ˆ F1 ë ˆì´ì‹± í˜ì´ìŠ¤ë¶F1 ë¯¸êµ­ ë¼ìŠ¤ë² ì´ê±°ìŠ¤ ëŒ€íšŒì—ì„œ ë§¥ìŠ¤ í˜ë¥´ìŠ¤íƒ€íœ(ë ˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 í˜ë¥´ìŠ¤íƒ€íœ â€œë‚´ë…„ ì‹œì¦Œì—” 3ë²ˆê³¼ 69ë²ˆìœ¼ë¡œ ë°”ê¾¸ê² ë‹¤\"</td>\n",
       "      <td>http://www.gpkorea.com/news/articleView.html?i...</td>\n",
       "      <td>ì‚¬ì§„=ë ˆë“œë¶ˆ ë ˆì´ì‹± í˜ì´ìŠ¤ë¶ë§¥ìŠ¤ í˜ë¥´ìŠ¤íƒ€íœì´ ë‚´ë…„ ì‹œì¦Œ ìì‹ ì˜ ê²½ì£¼ì°¨ ë„˜ë²„ë¡œ 3ê³¼ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>`í˜ë¼ë¦¬ F1 ì˜ì…ì„¤' í˜¸ë„ˆ...ìœŒë¦¬ì—„ìŠ¤-ìºë”œë½-ì• ìŠ¤í„´ë§ˆí‹´ì€ \"NO!\"</td>\n",
       "      <td>http://www.gpkorea.com/news/articleView.html?i...</td>\n",
       "      <td>ì‚¬ì§„=ë ˆë“œë¶ˆ ë ˆì´ì‹±í¬ë¦¬ìŠ¤ì²œ í˜¸ë„ˆ(51)ê°€ í˜ë¼ë¦¬ F1ì— ì „ê²© ì˜ì…ëœë‹¤ëŠ” ì†Œë¬¸ì´ ëŒê³ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>â€œF1ì—ì„œ ë°°ìš°ëŠ” ì¡°ì§ ì „ëµâ€â€¦ë³€ë™ì‹ ì „ í˜‘íšŒì¥ `F1 ë¦¬ë”ì‹­` ì¶œê°„</td>\n",
       "      <td>http://www.gpkorea.com/news/articleView.html?i...</td>\n",
       "      <td>ë³€ë™ì‹ ì „ ëŒ€í•œìë™ì°¨ê²½ì£¼í˜‘íšŒì¥ì´ ì‹ ê°„ â€˜F1Â ë¦¬ë”ì‹­(ë©”ë””ì¹˜ë¯¸ë””ì–´ í´ëƒ„)â€™ì„ ì„ ë³´ì—¬ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0       F1 ë§¥ë¼ë Œ ë…¸ë¦¬ìŠ¤Â·í”¼ì•„ìŠ¤íŠ¸ë¦¬ `ì¶©ê²©ì˜ ì‹¤ê²©`â€¦ìŠ¤í‚¤ë“œ ë¸”ë¡ ê·œì • ìœ„ë°˜   \n",
       "1  \"ì´ëŸ´ ìˆ˜ê°€...\" F1 í˜ë¥´ìŠ¤íƒ€íœ, ë¼ìŠ¤ë² ì´ê±°ìŠ¤GP ìš°ìŠ¹ '24ì ì°¨ ì¢í˜”ë‹¤'   \n",
       "2             F1 í˜ë¥´ìŠ¤íƒ€íœ â€œë‚´ë…„ ì‹œì¦Œì—” 3ë²ˆê³¼ 69ë²ˆìœ¼ë¡œ ë°”ê¾¸ê² ë‹¤\"   \n",
       "3      `í˜ë¼ë¦¬ F1 ì˜ì…ì„¤' í˜¸ë„ˆ...ìœŒë¦¬ì—„ìŠ¤-ìºë”œë½-ì• ìŠ¤í„´ë§ˆí‹´ì€ \"NO!\"   \n",
       "4       â€œF1ì—ì„œ ë°°ìš°ëŠ” ì¡°ì§ ì „ëµâ€â€¦ë³€ë™ì‹ ì „ í˜‘íšŒì¥ `F1 ë¦¬ë”ì‹­` ì¶œê°„   \n",
       "\n",
       "                                                link  \\\n",
       "0  http://www.gpkorea.com/news/articleView.html?i...   \n",
       "1  http://www.gpkorea.com/news/articleView.html?i...   \n",
       "2  http://www.gpkorea.com/news/articleView.html?i...   \n",
       "3  http://www.gpkorea.com/news/articleView.html?i...   \n",
       "4  http://www.gpkorea.com/news/articleView.html?i...   \n",
       "\n",
       "                                             context  \n",
       "0  ì‚¬ì§„=ë§¥ë¼ë Œ F1 íŒ€ í˜ì´ìŠ¤ë¶í¬ë®¬ëŸ¬ ì›(F1) ë§¥ë¼ë Œ íŒ€ì´ ë¼ìŠ¤ë² ì´ê±°ìŠ¤ ê·¸ë‘í”„ë¦¬ ê²°...  \n",
       "1  ì‚¬ì§„=ë ˆë“œë¶ˆ F1 ë ˆì´ì‹± í˜ì´ìŠ¤ë¶F1 ë¯¸êµ­ ë¼ìŠ¤ë² ì´ê±°ìŠ¤ ëŒ€íšŒì—ì„œ ë§¥ìŠ¤ í˜ë¥´ìŠ¤íƒ€íœ(ë ˆ...  \n",
       "2  ì‚¬ì§„=ë ˆë“œë¶ˆ ë ˆì´ì‹± í˜ì´ìŠ¤ë¶ë§¥ìŠ¤ í˜ë¥´ìŠ¤íƒ€íœì´ ë‚´ë…„ ì‹œì¦Œ ìì‹ ì˜ ê²½ì£¼ì°¨ ë„˜ë²„ë¡œ 3ê³¼ ...  \n",
       "3  ì‚¬ì§„=ë ˆë“œë¶ˆ ë ˆì´ì‹±í¬ë¦¬ìŠ¤ì²œ í˜¸ë„ˆ(51)ê°€ í˜ë¼ë¦¬ F1ì— ì „ê²© ì˜ì…ëœë‹¤ëŠ” ì†Œë¬¸ì´ ëŒê³ ...  \n",
       "4  ë³€ë™ì‹ ì „ ëŒ€í•œìë™ì°¨ê²½ì£¼í˜‘íšŒì¥ì´ ì‹ ê°„ â€˜F1Â ë¦¬ë”ì‹­(ë©”ë””ì¹˜ë¯¸ë””ì–´ í´ëƒ„)â€™ì„ ì„ ë³´ì—¬ ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52427e9d",
   "metadata": {},
   "source": [
    "### Trial 2 >> Autosport\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6e9939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosport ì ì… ì‹œë„: https://www.autosport.com/f1/news/\n",
      "ì‘ë‹µ ì½”ë“œ: 200\n",
      "ë§í¬ 568ê°œ ë¶„ì„ ì¤‘...\n",
      "âœ… [ë°œê²¬] Pirelli's C6 experiment didn't...\n",
      "âœ… [ë°œê²¬] Why Las Vegas was typical of F...\n",
      "âœ… [ë°œê²¬] Why there's no reason to panic...\n",
      "âœ… [ë°œê²¬] Tsunoda moans \"everything is g...\n",
      "âœ… [ë°œê²¬] Should McLaren back Norris now...\n",
      "âœ… [ë°œê²¬] Pirelli abandons C6 tyre as it...\n",
      "âœ… [ë°œê²¬] Antonelli \"didn't really feel\"...\n",
      "âœ… [ë°œê²¬] Ferrari must \"calm down\" after...\n",
      "âœ… [ë°œê²¬] McLaren telling Norris to atta...\n",
      "âœ… [ë°œê²¬] Why McLaren was the surprise c...\n",
      "ì„±ê³µ! 10ê°œì˜ ì˜ë¬¸ ê¸°ì‚¬ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.\n",
      "                                               title  \\\n",
      "0  Pirelli's C6 experiment didn't work - but nor ...   \n",
      "1  Why Las Vegas was typical of Ferrariâ€™s sub-opt...   \n",
      "2  Why there's no reason to panic for Norris and ...   \n",
      "3  Tsunoda moans \"everything is going against me\"...   \n",
      "4  Should McLaren back Norris now in F1 title fig...   \n",
      "\n",
      "                                                link     source  \n",
      "0  https://www.autosport.com/f1/news/pirellis-c6-...  Autosport  \n",
      "1  https://www.autosport.com/f1/news/las-vegas-ty...  Autosport  \n",
      "2  https://www.autosport.com/f1/news/why-theres-n...  Autosport  \n",
      "3  https://www.autosport.com/f1/news/everything-i...  Autosport  \n",
      "4  https://www.autosport.com/f1/news/should-mclar...  Autosport  \n"
     ]
    }
   ],
   "source": [
    "# Request ë¡œ 1ì°¨ ì‹œë„\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "def crawl_autosport_f1():\n",
    "    url = \"https://www.autosport.com/f1/news/\"\n",
    "    \n",
    "    # ë´‡ íƒì§€ë¥¼ í”¼í•˜ê¸° ìœ„í•œ ë¦¬ì–¼í•œ í—¤ë” ì„¤ì •\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Referer': 'https://www.google.com/'\n",
    "    }\n",
    "    \n",
    "    print(f\"Autosport ì ì… ì‹œë„: {url}\")\n",
    "    \n",
    "    try:\n",
    "        # íƒ€ì„ì•„ì›ƒ 10ì´ˆ ì„¤ì •\n",
    "        res = requests.get(url, headers=headers, timeout=10)\n",
    "        print(f\"ì‘ë‹µ ì½”ë“œ: {res.status_code}\") # 200ì´ë©´ ì„±ê³µ!\n",
    "        \n",
    "        if res.status_code == 403:\n",
    "            print(\"403 Forbidden: ë´‡ íƒì§€ë¨! (Selenium í•„ìš”)\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ì ‘ì† ì—ëŸ¬: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    articles = []\n",
    "    \n",
    "    # Autosport êµ¬ì¡°ìƒ ëª¨ë“  ë§í¬(a)ë¥¼ ê¸ì–´ì„œ ë‰´ìŠ¤ ë§í¬ë§Œ í•„í„°ë§í•˜ëŠ” ê²Œ ê°€ì¥ í™•ì‹¤í•¨\n",
    "    # (í´ë˜ìŠ¤ëª…ì´ ìì£¼ ë°”ë€Œê¸° ë•Œë¬¸)\n",
    "    links = soup.select(\"a\")\n",
    "    \n",
    "    print(f\"ë§í¬ {len(links)}ê°œ ë¶„ì„ ì¤‘...\")\n",
    "    \n",
    "    unique_links = set() # ì¤‘ë³µ ë°©ì§€ìš©\n",
    "    \n",
    "    for row in links:\n",
    "        title = row.get_text(strip=True)\n",
    "        href = row.get('href', '')\n",
    "        \n",
    "        # í•„í„°ë§ ì¡°ê±´:\n",
    "        # 1. ë§í¬ì— '/f1/news/'ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨\n",
    "        # 2. ì œëª© ê¸¸ì´ê°€ ì ë‹¹íˆ ê¸¸ì–´ì•¼ í•¨ (ë©”ë‰´ ë²„íŠ¼ ì œì™¸)\n",
    "        # 3. ì¤‘ë³µëœ ë§í¬ê°€ ì•„ë‹ˆì–´ì•¼ í•¨\n",
    "        if '/f1/news/' in href and len(title) > 15:\n",
    "            full_link = \"https://www.autosport.com\" + href if not href.startswith('http') else href\n",
    "            \n",
    "            if full_link not in unique_links:\n",
    "                unique_links.add(full_link)\n",
    "                \n",
    "                print(f\"âœ… [ë°œê²¬] {title[:30]}...\") # ì œëª©ì´ ê¸°ë‹ˆê¹Œ ì•ë¶€ë¶„ë§Œ\n",
    "                \n",
    "                articles.append({\n",
    "                    \"title\": title,\n",
    "                    \"link\": full_link,\n",
    "                    \"source\": \"Autosport\"\n",
    "                })\n",
    "                \n",
    "                if len(articles) >= 10: # í…ŒìŠ¤íŠ¸ë‹ˆê¹Œ 10ê°œë§Œ\n",
    "                    break\n",
    "    \n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "df_autosport = crawl_autosport_f1()\n",
    "\n",
    "if not df_autosport.empty:\n",
    "    print(f\"ì„±ê³µ! {len(df_autosport)}ê°œì˜ ì˜ë¬¸ ê¸°ì‚¬ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(df_autosport.head())\n",
    "else:\n",
    "    print(\"\\nì•„ë¬´ê²ƒë„ ëª» ê±´ì¡Œê±°ë‚˜ ì°¨ë‹¨ë‹¹í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dfe7348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pirelli's C6 experiment didn't work - but nor ...</td>\n",
       "      <td>https://www.autosport.com/f1/news/pirellis-c6-...</td>\n",
       "      <td>Autosport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why Las Vegas was typical of Ferrariâ€™s sub-opt...</td>\n",
       "      <td>https://www.autosport.com/f1/news/las-vegas-ty...</td>\n",
       "      <td>Autosport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why there's no reason to panic for Norris and ...</td>\n",
       "      <td>https://www.autosport.com/f1/news/why-theres-n...</td>\n",
       "      <td>Autosport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tsunoda moans \"everything is going against me\"...</td>\n",
       "      <td>https://www.autosport.com/f1/news/everything-i...</td>\n",
       "      <td>Autosport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Should McLaren back Norris now in F1 title fig...</td>\n",
       "      <td>https://www.autosport.com/f1/news/should-mclar...</td>\n",
       "      <td>Autosport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Pirelli's C6 experiment didn't work - but nor ...   \n",
       "1  Why Las Vegas was typical of Ferrariâ€™s sub-opt...   \n",
       "2  Why there's no reason to panic for Norris and ...   \n",
       "3  Tsunoda moans \"everything is going against me\"...   \n",
       "4  Should McLaren back Norris now in F1 title fig...   \n",
       "\n",
       "                                                link     source  \n",
       "0  https://www.autosport.com/f1/news/pirellis-c6-...  Autosport  \n",
       "1  https://www.autosport.com/f1/news/las-vegas-ty...  Autosport  \n",
       "2  https://www.autosport.com/f1/news/why-theres-n...  Autosport  \n",
       "3  https://www.autosport.com/f1/news/everything-i...  Autosport  \n",
       "4  https://www.autosport.com/f1/news/should-mclar...  Autosport  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_autosport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfaa2e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosport ì ‘ê·¼ ì¤‘: https://www.autosport.com/f1/news/\n",
      "ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ ë¶„ì„ ë° ë³¸ë¬¸ ìˆ˜ì§‘ ì‹œì‘...\n",
      "[Target] Pirelli's C6 experiment didn't work - bu...\n",
      "  â”” ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ (2996ì)\n",
      "[Target] Why Las Vegas was typical of Ferrariâ€™s s...\n",
      "  â”” ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ (6502ì)\n",
      "[Target] Why there's no reason to panic for Norri...\n",
      "  â”” ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ (7526ì)\n",
      "[Target] Tsunoda moans \"everything is going again...\n",
      "  â”” ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ (4437ì)\n",
      "[Target] Should McLaren back Norris now in F1 tit...\n",
      "  â”” ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ (9492ì)\n",
      "\n",
      "ì„±ê³µ! ì´ 5ê°œì˜ ê¸°ì‚¬ ë³¸ë¬¸ê¹Œì§€ í™•ë³´í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[ì²« ë²ˆì§¸ ê¸°ì‚¬ ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°]\n",
      "Manage alerts on breaking news and favorite drivers Razgatlioglu aims to challenge Quartararo in rookie MotoGP season Pirelli's C6 experiment didn't work - but nor have the other 2025 F1 tyre trials Why Las Vegas was typical of Ferrariâ€™s sub-optimal 2025 F1 season How Toyota is revamping its GR010 L...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "# --- 1. ê³µí†µ í—¤ë” (ìŠ¤í…”ìŠ¤ ëª¨ë“œ) ---\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Referer': 'https://www.google.com/'\n",
    "}\n",
    "\n",
    "def extract_autosport_content(url):\n",
    "    \"\"\"\n",
    "    [ìˆ˜ì •ë²„ì „] í´ë˜ìŠ¤ ì´ë¦„ ì˜ì¡´ì„±ì„ ì œê±°í•˜ê³ , \n",
    "    ëª¨ë“  píƒœê·¸ë¥¼ ê¸ì–´ì„œ ê¸°ì‚¬ ê°™ì€ ê²ƒë§Œ ë‚¨ê¸°ëŠ” ë°©ì‹\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ë§¤ë„ˆ ë”œë ˆì´\n",
    "        time.sleep(random.uniform(1.0, 2.0))\n",
    "        \n",
    "        res = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        if res.status_code != 200:\n",
    "            print(f\"  â”” ì ‘ì† ì‹¤íŒ¨ (Code: {res.status_code})\")\n",
    "            return \"\"\n",
    "            \n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        \n",
    "        # 1. ë´‡ ì°¨ë‹¨ ì—¬ë¶€ í™•ì¸ (í˜¹ì‹œ ìº¡ì°¨ê°€ ë–´ëŠ”ì§€ í™•ì¸)\n",
    "        page_title = soup.title.get_text(strip=True) if soup.title else \"No Title\"\n",
    "        if \"Bot\" in page_title or \"Access Denied\" in page_title:\n",
    "             print(f\"  â”” ğŸš¨ ë´‡ íƒì§€ë¨! (Page Title: {page_title})\")\n",
    "             return \"\"\n",
    "\n",
    "        # 2. [ì „ëµ ë³€ê²½] íŠ¹ì • Div ì°¾ì§€ ë§ê³ , ê·¸ëƒ¥ ëª¨ë“  p íƒœê·¸ ê°€ì ¸ì˜¤ê¸°\n",
    "        # Autosport ê¸°ì‚¬ëŠ” ë³´í†µ article íƒœê·¸ë‚˜ main íƒœê·¸ ì•ˆì— ìˆìŠµë‹ˆë‹¤.\n",
    "        # ë²”ìœ„ë¥¼ ì¢íˆê¸° ìœ„í•´ article íƒœê·¸ ë¨¼ì € ì‹œë„, ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ ì°¾ê¸°\n",
    "        container = soup.find('article')\n",
    "        if not container:\n",
    "            container = soup # ì—†ìœ¼ë©´ ì „ì²´ HTMLì—ì„œ ì°¾ìŒ\n",
    "            \n",
    "        paragraphs = container.find_all('p')\n",
    "        \n",
    "        clean_text = []\n",
    "        for p in paragraphs:\n",
    "            text = p.get_text(strip=True)\n",
    "            \n",
    "            # 3. [ë…¸ì´ì¦ˆ í•„í„°ë§]\n",
    "            # - ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ (ë©”ë‰´, ë§í¬ ë“±) ì œì™¸ (50ì ì´ìƒë§Œ)\n",
    "            # - 'Read Also', 'Photo by' ê°™ì€ ê±° ì œì™¸\n",
    "            if len(text) > 50 and \"Read Also:\" not in text and \"Photo by\" not in text:\n",
    "                clean_text.append(text)\n",
    "        \n",
    "        # ìˆ˜ì§‘ëœ ë¬¸ì¥ì´ 3ê°œ ë¯¸ë§Œì´ë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼ (ë„ˆë¬´ ì ìŒ)\n",
    "        if len(clean_text) < 3:\n",
    "            print(f\"  â”” í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ (ìœ íš¨ ë¬¸ì¥ ë¶€ì¡±, HTML êµ¬ì¡° í™•ì¸ í•„ìš”)\")\n",
    "            # ë””ë²„ê¹…ìš©: ë„ëŒ€ì²´ ë­˜ ê°€ì ¸ì™”ëŠ”ì§€ í™•ì¸\n",
    "            # print(f\"    (Debug: Page Title - {page_title})\") \n",
    "            return \"\"\n",
    "\n",
    "        return \" \".join(clean_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  â”” ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def crawl_autosport_full():\n",
    "    \"\"\"\n",
    "    ëª©ë¡ ìˆ˜ì§‘ + ë³¸ë¬¸ ìˆ˜ì§‘ì„ í•©ì¹œ ë©”ì¸ í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.autosport.com/f1/news/\"\n",
    "    print(f\"Autosport ì ‘ê·¼ ì¤‘: {base_url}\")\n",
    "    \n",
    "    res = requests.get(base_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    \n",
    "    links = soup.select(\"a\")\n",
    "    articles = []\n",
    "    unique_links = set()\n",
    "    \n",
    "    print(\"ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ ë¶„ì„ ë° ë³¸ë¬¸ ìˆ˜ì§‘ ì‹œì‘...\")\n",
    "    \n",
    "    count = 0\n",
    "    for row in links:\n",
    "        title = row.get_text(strip=True)\n",
    "        href = row.get('href', '')\n",
    "        \n",
    "        # í•„í„°ë§: F1 ë‰´ìŠ¤ ë§í¬ì´ê³  ì œëª©ì´ ì¢€ ê¸´ ê²ƒ\n",
    "        if '/f1/news/' in href and len(title) > 20:\n",
    "            full_link = \"https://www.autosport.com\" + href if not href.startswith('http') else href\n",
    "            \n",
    "            if full_link not in unique_links:\n",
    "                unique_links.add(full_link)\n",
    "                print(f\"[Target] {title[:40]}...\")\n",
    "                \n",
    "                # â˜… ì—¬ê¸°ì„œ ë³¸ë¬¸ ì¶”ì¶œ í•¨ìˆ˜ í˜¸ì¶œ!\n",
    "                content = extract_autosport_content(full_link)\n",
    "                \n",
    "                if content:\n",
    "                    articles.append({\n",
    "                        \"title\": title,\n",
    "                        \"link\": full_link,\n",
    "                        \"context\": content, # ì´ê²Œ ìš°ë¦¬ê°€ ì›í•˜ë˜ ê²ƒ!\n",
    "                        \"source\": \"Autosport\"\n",
    "                    })\n",
    "                    print(f\"  â”” ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ ({len(content)}ì)\")\n",
    "                    count += 1\n",
    "                else:\n",
    "                    print(\"  â”” ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨ (Skipped)\")\n",
    "                \n",
    "                if count >= 5: # í…ŒìŠ¤íŠ¸ë‹ˆê¹Œ 5ê°œë§Œ í•©ì‹œë‹¤\n",
    "                    break\n",
    "    \n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "# --- ì‹¤í–‰ ---\n",
    "df_autosport_full = crawl_autosport_full()\n",
    "\n",
    "if not df_autosport_full.empty:\n",
    "    print(f\"\\nì„±ê³µ! ì´ {len(df_autosport_full)}ê°œì˜ ê¸°ì‚¬ ë³¸ë¬¸ê¹Œì§€ í™•ë³´í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    # ì²« ë²ˆì§¸ ê¸°ì‚¬ì˜ ë³¸ë¬¸ ì•ë¶€ë¶„ë§Œ ì‚´ì§ ë§›ë³´ê¸°\n",
    "    print(\"\\n[ì²« ë²ˆì§¸ ê¸°ì‚¬ ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°]\")\n",
    "    print(df_autosport_full.iloc[0]['context'][:300] + \"...\")\n",
    "else:\n",
    "    print(\"\\nìˆ˜ì§‘ ì‹¤íŒ¨. í—¤ë”ë‚˜ ì„ íƒìë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30725e55",
   "metadata": {},
   "source": [
    "### Trial 3\n",
    "\n",
    "- F1 ê³µí™ˆ >> Race Strategy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49af04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a22a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¤‘ì¥ë¹„(Selenium) ê°€ë™: Analysis ì„¹ì…˜ ê³µëµ...\n",
      "ğŸŒ ì§„ì… URL: https://www.formula1.com/en/latest/tags/analysis.3HkjTN75peeCOsSegCyOWi\n",
      "ì „ì²´ ë§í¬ 150ê°œ 1ì°¨ ìŠ¤ìº” ì¤‘...\n",
      "  [Target] What are the tactical options for the La...\n",
      "  [Target] Did Piastri deserve his penalty in Sao P...\n",
      "  [Target] What are the tactical options for the Sa...\n",
      "  [Target] What are the tactical options for the Me...\n",
      "  [Target] What are the tactical options for the Un...\n",
      "  [Target] Are Russell and Antonelli Mercedes' long...\n",
      "  [Target] What are the tactical options for the Si...\n",
      "  [Target] What are the tactical options for the Az...\n",
      "  [Target] What are the tactical options for the It...\n",
      "  [Target] Why Alpine were keen to lock down Gasly ...\n",
      "  [Target] Why Cadillac decided to go for Perez and...\n",
      "  [Target] What are the tactical options for the Hu...\n",
      "  [Target] What are the tactical options for the Be...\n",
      "  [Target] The key questions as Horner leaves Red B...\n",
      "  [Target] What are the tactical options for the Br...\n",
      "  [Target] What are the tactical options for the Au...\n",
      "ì´ 16ê°œì˜ ë¶„ì„ ë¦¬í¬íŠ¸ í›„ë³´ ì„ ì • ì™„ë£Œ.\n",
      "  ë³¸ë¬¸ ì¶”ì¶œ ì¤‘: What are the tactica...\n"
     ]
    }
   ],
   "source": [
    "def crawl_f1_analysis_only():\n",
    "    chrome_options = Options()\n",
    "    # â˜… WSL í™˜ê²½ í•„ìˆ˜ ì˜µì…˜ (í—¤ë“œë¦¬ìŠ¤)\n",
    "    chrome_options.add_argument(\"--headless\") \n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"window-size=1920,1080\")\n",
    "    \n",
    "    # ë´‡ íƒì§€ íšŒí”¼ í—¤ë”\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "    print(\"ì¤‘ì¥ë¹„(Selenium) ê°€ë™: Analysis ì„¹ì…˜ ê³µëµ...\")\n",
    "    \n",
    "    # ë“œë¼ì´ë²„ ì‹¤í–‰\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    \n",
    "    # â˜… íƒ€ê²Ÿ ë³€ê²½: Analysis íƒœê·¸ í˜ì´ì§€ (ì—¬ê¸°ê°€ ì „ëµ ë¦¬í¬íŠ¸ ë§›ì§‘)\n",
    "    url = \"https://www.formula1.com/en/latest/tags/analysis.3HkjTN75peeCOsSegCyOWi\"\n",
    "    print(f\"ì§„ì… URL: {url}\")\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(3) # ë¡œë”© ëŒ€ê¸°\n",
    "        \n",
    "        # ì¿ í‚¤ íŒì—… ì²˜ë¦¬ (í˜¹ì‹œ ëœ¨ë©´ ë‹«ê¸°)\n",
    "        try:\n",
    "            cookie_btn = driver.find_element(By.ID, \"sp-cc-accept\")\n",
    "            cookie_btn.click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # ë§í¬ ìˆ˜ì§‘ ì‹œì‘\n",
    "        links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "        print(f\"ì „ì²´ ë§í¬ {len(links)}ê°œ 1ì°¨ ìŠ¤ìº” ì¤‘...\")\n",
    "        \n",
    "        target_links = []\n",
    "        seen_urls = set() # ì¤‘ë³µ URL ë°©ì§€ìš©\n",
    "        \n",
    "        for link in links:\n",
    "            try:\n",
    "                href = link.get_attribute('href')\n",
    "                title = link.text.strip()\n",
    "                \n",
    "                # â˜… í•„í„°ë§ ê°•í™” (Strict Mode) â˜…\n",
    "                # 1. ì£¼ì†Œì— '/en/latest/article'ì´ ìˆì–´ì•¼ í•¨ (ë‰´ìŠ¤ ê¸°ì‚¬ë§Œ)\n",
    "                # 2. ì œëª©(title)ì´ ë¹„ì–´ìˆìœ¼ë©´ ì•ˆ ë¨ (ì´ë¯¸ì§€ ë§í¬, ì•„ì´ì½˜ ë“± ì œì™¸)\n",
    "                # 3. 'Video' ë‚˜ 'Podcast'ëŠ” ì œì™¸ (í…ìŠ¤íŠ¸ ë¶„ì„ìš©ì´ë‹ˆê¹Œ)\n",
    "                if href and '/en/latest/article' in href and title:\n",
    "                    \n",
    "                    if \"Video\" not in title and \"Podcast\" not in title:\n",
    "                        if href not in seen_urls:\n",
    "                            seen_urls.add(href)\n",
    "                            target_links.append({\"href\": href, \"title\": title})\n",
    "                            print(f\"  [Target] {title[:40]}...\")\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        print(f\"ì´ {len(target_links)}ê°œì˜ ë¶„ì„ ë¦¬í¬íŠ¸ í›„ë³´ ì„ ì • ì™„ë£Œ.\")\n",
    "        \n",
    "        # ë³¸ë¬¸ ìˆ˜ì§‘ (ìƒìœ„ 5ê°œë§Œ)\n",
    "        articles = []\n",
    "        for target in target_links[:5]:\n",
    "            print(f\"  ë³¸ë¬¸ ì¶”ì¶œ ì¤‘: {target['title'][:20]}...\")\n",
    "            \n",
    "            try:\n",
    "                driver.get(target['href'])\n",
    "                time.sleep(random.uniform(1.5, 3.0))\n",
    "                \n",
    "                # ë³¸ë¬¸ ì¶”ì¶œ (p íƒœê·¸ ì „ì²´ ìŠ¤ìº” ì „ëµ)\n",
    "                paragraphs = driver.find_elements(By.TAG_NAME, \"p\")\n",
    "                \n",
    "                content = []\n",
    "                for p in paragraphs:\n",
    "                    text = p.text.strip()\n",
    "                    # ë…¸ì´ì¦ˆ ì œê±°: ë„ˆë¬´ ì§§ê±°ë‚˜ ì¿ í‚¤/ì €ì‘ê¶Œ ê´€ë ¨ ë¬¸êµ¬ ì œì™¸\n",
    "                    if len(text) > 40 and \"cookie\" not in text.lower() and \"Â©\" not in text:\n",
    "                        content.append(text)\n",
    "                \n",
    "                full_text = \" \".join(content)\n",
    "                \n",
    "                if len(full_text) > 500: # ë‚´ìš©ì´ ì¶©ë¶„í•œ ê²½ìš°ë§Œ ì €ì¥\n",
    "                    articles.append({\n",
    "                        \"title\": target['title'],\n",
    "                        \"link\": target['href'],\n",
    "                        \"context\": full_text,\n",
    "                        \"source\": \"F1 Official Analysis\"\n",
    "                    })\n",
    "                    print(f\"    ì„±ê³µ ({len(full_text)}ì)\")\n",
    "                else:\n",
    "                    print(\"    ì‹¤íŒ¨ (ë‚´ìš© ë¶€ì¡±)\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    ì—ëŸ¬: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ì¹˜ëª…ì  ì—ëŸ¬: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        \n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "df_analysis = crawl_f1_analysis_only()\n",
    "\n",
    "if not df_analysis.empty:\n",
    "    print(f\"\\nìµœì¢… ê²°ê³¼: {len(df_analysis)}ê°œì˜ ê³ í’ˆì§ˆ ì „ëµ ë¦¬í¬íŠ¸ í™•ë³´!\")\n",
    "    print(df_analysis[['title']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cecbacef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>context</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the tactical options for the Las Vega...</td>\n",
       "      <td>https://www.formula1.com/en/latest/article/str...</td>\n",
       "      <td>Matt Youson takes a look at the different pit ...</td>\n",
       "      <td>F1 Official Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did Piastri deserve his penalty in Sao Paulo?</td>\n",
       "      <td>https://www.formula1.com/en/latest/article/pal...</td>\n",
       "      <td>Former F1 driver Jolyon Palmer breaks down the...</td>\n",
       "      <td>F1 Official Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the tactical options for the Sao Paul...</td>\n",
       "      <td>https://www.formula1.com/en/latest/article/str...</td>\n",
       "      <td>Matt Youson takes a look at the different pit ...</td>\n",
       "      <td>F1 Official Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the tactical options for the Mexico C...</td>\n",
       "      <td>https://www.formula1.com/en/latest/article/str...</td>\n",
       "      <td>Matt Youson takes a look at the different pit ...</td>\n",
       "      <td>F1 Official Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the tactical options for the United S...</td>\n",
       "      <td>https://www.formula1.com/en/latest/article/str...</td>\n",
       "      <td>Matt Youson takes a look at the different pit ...</td>\n",
       "      <td>F1 Official Analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  What are the tactical options for the Las Vega...   \n",
       "1      Did Piastri deserve his penalty in Sao Paulo?   \n",
       "2  What are the tactical options for the Sao Paul...   \n",
       "3  What are the tactical options for the Mexico C...   \n",
       "4  What are the tactical options for the United S...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.formula1.com/en/latest/article/str...   \n",
       "1  https://www.formula1.com/en/latest/article/pal...   \n",
       "2  https://www.formula1.com/en/latest/article/str...   \n",
       "3  https://www.formula1.com/en/latest/article/str...   \n",
       "4  https://www.formula1.com/en/latest/article/str...   \n",
       "\n",
       "                                             context                source  \n",
       "0  Matt Youson takes a look at the different pit ...  F1 Official Analysis  \n",
       "1  Former F1 driver Jolyon Palmer breaks down the...  F1 Official Analysis  \n",
       "2  Matt Youson takes a look at the different pit ...  F1 Official Analysis  \n",
       "3  Matt Youson takes a look at the different pit ...  F1 Official Analysis  \n",
       "4  Matt Youson takes a look at the different pit ...  F1 Official Analysis  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
